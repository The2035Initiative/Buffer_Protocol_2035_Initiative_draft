---
title: "Buffer_Protocol_Rough_Draft"
author: "Sofia Ingersoll"
format: html
editor: visual
---

*Rough Draft pls no judging yet*

# Protocol for Creating Buffer Zones & Selecting Random Addresses in Buffer Regions

The following code describes a step-by-step process for creating a map containing buffer zones around points of interest. In this documentation, the data utilized is the [US Wind Data](https://dataverse.harvard.edu/file.xhtml?fileId=7339850&version=1.0), this data is associated with the "Replication Data for: Prevalence and predictors of wind energy opposition in North America",Â <https://doi.org/10.7910/DVN/LE2V0R>, Harvard Dataverse, V1, 2023. The collaborators on that project include: Stokes, Leah; Franzblau, Emma; Lovering, Jessica R.; Miljanich, Chris.

\~ include more about what the data is about and the outcomes of making visualization \~

Analysis of these areas will provide insight into local resistance and spatially distorted signalling in relation to wind power infrastructure and climate policy.

### Loading Libraries

The following libraries were selected based on their functionality and ability to optimize our data for mapping.

```{r, message = FALSE}
# Loading Libraries
library(tidyverse)        # essential r package 
library(sf)               # package simplifies spatial dataframes
library(raster)
library(tmap)
library(terra)
library(stars)
library(smoothr)          # aesthetic and visual aid for buffers created
```

### Read in the Data

To simplify the following step, it is important to organize your folders in a way that makes sense for your workflow. In many cases, the data sets we work with are typically too large to be uploaded to GitHub. As a result, a common practice is storing your data in a folder, directly outside of your repository in a folder labeled "data".

The code chunk below for `read.csv` demonstrates how to exit your current location using `..` and enter the desired folder location using `/`. It is important that your file path does not contain any spaces and is directly reflective of the file path for the data you wish to read in.

#### U.S. Wind Data

```{r}
# reading in & storing data
wind_data <- read.csv("../data/wind_data/wind_data_usa.csv")  
```

##### Confirm the Data Loaded Properly

```{r}
head(wind_data)                  # displays the first 6 rows of the data
                                 # along with all of the columns 
```

#### EJ Screen Data

```{r include=TRUE, eval=FALSE, warning=FALSE, error=FALSE}
ejscreen <- st_read("../data/EJSCREEN_2023_BG_StatePct_with_AS_CNMI_GU_VI.gdb",
                    quiet = TRUE)
# reads in raster data using the sf package st_read function
# the quiet T/F input refers to information output after importing data
```

## Wrangling & Subsetting

want:

-   a scalable map of USA w/ state boundaries

-   the name of the plants as points

-   adjustable buffer zones (donuts) around the plants

-   ability to randomly select addresses within the buffer

-   filter for specific groups of interest

### **Converting lat/long into Raster Data (i.e. sticky geometries)**

Below we will use the package `sf` to convert the lat/long data into a raster geometry column. In this single line, we will also be assigning the CRS EPSG:4326 to the sf data frame. The CRS was selected because it provides a relatively proportionate display of the United States. We are open to suggestions regarding our CRS if a different project better fits our data.

```{r}
wind_sf <- wind_data %>%             # calls desired dataset
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) 
                                     # creates geometry column with desired crs 
```

#### Check-point

Let's stop and see if our outputs are what we expect.

Were the lat/long columns correctly converted into a geometry column?

`setdiff()` is a way to quickly determine the differences between two data sets.

```{r}
setdiff(wind_data, wind_sf)
```

```{r}
# checking column names
print(colnames(wind_data))

print(colnames(wind_sf))
```

#### **Confirm CRS is correct**

Coordinate Reference Systems, CRS, are required in order for the data to be projected onto a map.

```{r}
glimpse(crs(wind_sf))                  # output should reveal WGS84, EPSG:4326
```

## Initial Visualization of the Data

Using the base R function `plot()`, we can see that the geometries stored by this data set correlate to the locations of wind infrastructure plants throughout the United States. In order to visualize these locations with respect to state and county jurisdictions, we'll need to utilize another data set to create a base layer for our map.

```{r}
# First visual of the U.S. wind data provided by the geometry points
plot(wind_sf$geometry)
```

### Creating a Base Map Layer

```{r}
ggplot() +
  geom_sf(data = ejscreen) +
  geom_sf(data = wind_sf) 
```

*ggplot psuedocode*

```{r}
# group by state
```

*Fourth Attempt but EJ Screen Data*

The issue with the ejscreen data are the inclusion of US territories found in region 9. Below I am working on a process to filter out those specific locations from the data without removing desired states in the Pacific region.

#### Regions of Interest

[Region Codes](https://ncsesdata.nsf.gov/docs/location.html) reveals the various regions throughout the US that are identifiable using codes between 1:10. US Territories are categorized under the Pacific Region Code, 9. Other states like CA, OR, HA, AK, and WA are also in the Pacific Region.

```{r}
unique(ejscreen$REGION)
```

#### Identifying the State Names for US Territories

To properly filter out these unwanted observations, it's best to identify the exact names of the unwanted regions. We can do this using the `unique` function on the state_name column.

```{r}
print(unique(ejscreen$STATE_NAME))
```

#### Removing Regions Outside of Interest

**not subsetting properly, maybe use** `subset()`

```{r}
nonmapping_territories <- c('Puerto Rico', 'Guam', 'Virgin Islands', 'Northern Mariana IS', 'American Samoa')

us_basemap_data <- ejscreen %>% 
  filter(STATE_NAME != nonmapping_territories) %>% 
  filter(REGION != 10) %>% 
  group_by(STATE_NAME)
```

#### Next Idea: Create a Mask using US Country Coordinates

[Geojson Coordinate Mapper for Masks](http://geojson.io/#map=2.59/42.2/-96.48)

The regions of interest within of the United States are contained within the following coordinates:

**( A helpful shortcut to fix indentation is highlighting any script and using ctrl+i )**

-   `(-127.53756028744647, 48.89026620120862),`

-   `(-127.53756028744647, 24.9290443910311),`

-   `(-66.66926544935788, 24.9290443910311),`

-   `(-127.53756028744647, 48.89026620120862)`

These coordinates were then turned into a polygon using `st_polygon` and further converted into a simple feature collection (sfc) using `st_sfc()`. The CRS of this sfc was then converted to match the map to perform the crop.

The coordinates were selected using [geojson.io](geojson by Mapbox).

Our approach to mapping the entire region of interest, we will make polygons to represent Alaska, Hawaii, and mainland United States and combine them together to make a mask. This mask will then be used to crop the EJSCREEN data, optimizing it for mapping the regions containing information on public opinions and wind power infrastructure.

#### Creating Polygons for Regions of Interest (roi)

```{r}
# creating polygons that represent our regions of interest (roi)

mainland_states <- st_polygon(                            # creates a polygon with sf sticky geometries
  list(                                                   # stores the values as a list
    rbind(                                                # binds the following coordinates into a list
      c(-127.53756028744647,                              # coordinates of the polygon roi
        48.89026620120862),
      c(-127.53756028744647,
        24.9290443910311),
      c(-66.66926544935788,
        24.9290443910311),
      c(-66.66926544935788,
        48.89026620120862),
      c(-127.53756028744647,
        48.89026620120862)
    )
  )
) %>% 
  st_sfc(mainland_states) %>%                             # creates a special feature collection 
  st_set_crs(4326) %>%                                    # assigns a CRS that matches our data sets
  st_make_valid()                                         # corrects and invalid geometries 

alaska <- st_polygon(
  list(
    rbind(
      c(-140.2228758707459,
        51.668928934953044),
      c(-140.2228758707459,
        71.43126120088658),
      c(-195.54541333159068,
        71.43126120088658),
      c( -195.54541333159068,
         51.668928934953044),
      c(-140.2228758707459,
        51.668928934953044)
    )
  )
) %>% 
  st_sfc(alaska) %>%                           
  st_set_crs(4326) %>%                                    
  st_make_valid()

hawaii <- st_polygon(
  list(
    rbind(
      c( -154.04703346642728,
         18.040468043330847),
      c(-154.04703346642728,
        22.729375583644853),
      c( -160.94922236072725,
         22.729375583644853),
      c(-160.94922236072725,
        18.040468043330847),
      c(-154.04703346642728,
        18.040468043330847)
    )
  )
) %>% 
  st_sfc(hawaii) %>%                        
  st_set_crs(4326) %>%                                    
  st_make_valid()
```

#### Making a Multipolygon

```{r}
states_polygon <- st_multipolygon(list(mainland_states, alaska, hawaii))
```

*Preliminary Plot of Cropped EJScreen*

```{r}
ggplot() +
  geom_sf(data = ejscreen_cropped) +
  geom_sf(data = wind_sf) +
  theme_bw()
```

**improperly subset, so unable to map**

```{r}
tmap_mode('view')

tm_shape(us_basemap_data) +
  tm_shape(wind_sf) 

```

```{r}
ggplot() +
  geom_sf(data = us_basemap_data) +
  geom_sf(data = wind_sf) +
  theme_bw() +
  labs(title = "US Wind Infrastructure Plants") 
 # annotation_scale(plot_unit = "km") + # add scale bar
  #annotation_north_arrow( # add north arrorw
   # location = "tr",
    #pad_x = unit(0.2, "in"),
    #pad_y = unit(0.2, "in"),
    #style = ggspatial::north_arrow_nautical( # customize north arrow
     # fill = c("grey40", "white"),
    #  line_col = "grey20"
    #)
#  )

```

## Subsetting Wind Plant Locations in US

\*\* double check written description here \*\*

The code below selects only coordinates that intersect with the wind data and us mapping information

```{r}
# wind_sf <- wind_sf[us_basemap_data,]       # creates a combined subset of the                                                   wind data and the us}
```

## Buffers

Buffers create polygons representing a set distance from a feature.

The buffer zone dimensions were selected to correlate with the research presented in "Replication Data for: Prevalence and predictors of wind energy opposition in North America".

**Below is psuedocode for now until the cleaning is configured right**

```{r include=TRUE}
wind_data_buffer <- st_buffer(wind_sf, dist = 3000)
```

### Final Base Map of US

-   Need to include state lines for greater understanding and accuracy for collecting addresses

```{r}

```

**tmap psuedocode**

```{r}
tmap_mode('view')

tm_shape(wind_sf) +
  tm_polygons() +
  tm_symbols('plant_name')
```

```{r include=TRUE}
tm_shape(wind_data_buffer) +
  tm_polygons()
```

## Randomly Selecting Addresses Within Buffer Zones

```{r}

```

## Multivariate Linear Regression Models

```{r}

```

## Interpreting Omitted Variable Bias (OVB)

```{r}

```

## Logit

```{r}

```

## Log Odds

```{r}

```
